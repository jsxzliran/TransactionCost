{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":47354,"status":"ok","timestamp":1679299203724,"user":{"displayName":"rua rua","userId":"08327814307539928376"},"user_tz":0},"id":"Sx-3-Hjrfpj1","outputId":"d15b2acb-073f-4914-b57f-681465096f52"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","import sys\n","drive.mount('/content/drive')\n","sys.path.append('/content/drive/MyDrive/')"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":4152,"status":"ok","timestamp":1679299210421,"user":{"displayName":"rua rua","userId":"08327814307539928376"},"user_tz":0},"id":"9Q1nvElkevb7"},"outputs":[],"source":["import Data_generator_multiple as dg\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","from torch.nn import functional as F\n","from torch.autograd import Variable\n","from torch.cuda.amp import autocast, GradScaler\n","from torch import optim\n","import math, random\n","from mpl_toolkits.mplot3d import Axes3D\n","import matplotlib.pyplot as plt\n","from matplotlib import animation\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_YoQIoJ_ghEI"},"outputs":[],"source":["# initialize seed, mu, sigma, S0, paths, steps, T\n","# Clear pytorch cache\n","torch.cuda.empty_cache()\n","\n","# Set model parameters\n","seed = 32\n","num_stocks = 2\n","total_path = 30000\n","n_partition = 10\n","npaths = int(total_path/n_partition)\n","seq_length = 240\n","T=10\n","s0=np.array([1,1])\n","mu = np.array([0.12, 0.12])\n","#mu = np.array([0.0362, 0.0036])\n","k = 0.075\n","#cov = np.array([[0.0225, 0.00132],[0.00132, 0.0016]])\n","cov = np.array([[0.4-k, k],[k, 0.4-k]])\n","trade_cost = [0.01,0.01]\n","utility_gamma = 2.000\n","\n","# Set Simulation parameters: Notice that initial_rotate_matrix should be well guessed\n","n_epochs = 70\n","learning_rate = 0.01"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KCmEOqcKr34_"},"outputs":[],"source":["# initialize seed, mu, sigma, S0, paths, steps, T\n","# Clear pytorch cache\n","torch.cuda.empty_cache()\n","\n","# Set model parameters\n","seed = 36\n","num_stocks = 3\n","npaths = 30000\n","seq_length = 240\n","T=10\n","s0=np.array([1,1,1])\n","mu = np.array([0.12, 0.12, 0.12])\n","cov = 0.0*np.ones([3,3])\n","np.fill_diagonal(cov,0.16)\n","trade_cost = [0.01,0.01,0.01]\n","utility_gamma = 2.000\n","\n","# Set Simulation parameters: Notice that initial_rotate_matrix should be well guessed\n","n_epochs = 60\n","learning_rate = 0.01"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v5J2deThyaGz"},"outputs":[],"source":["# initialize seed, mu, sigma, S0, paths, steps, T\n","# Clear pytorch cache\n","torch.cuda.empty_cache()\n","\n","# Set model parameters\n","seed = 36\n","num_stocks = 10\n","total_path = 40000\n","n_partition = 10\n","npaths = int(total_path/n_partition)\n","seq_length = 240\n","T=10\n","s0=np.array([1,1,1,1,1,1,1,1,1,1])\n","mu = 0.12*s0\n","cov = 0.032*np.ones([num_stocks,num_stocks])\n","np.fill_diagonal(cov,0.16)\n","trade_cost = [0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01,0.01]\n","utility_gamma = 2.000\n","\n","# Set Simulation parameters: Notice that initial_rotate_matrix should be well guessed\n","n_epochs = 30\n","learning_rate = 0.01"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":226,"status":"ok","timestamp":1679299218963,"user":{"displayName":"rua rua","userId":"08327814307539928376"},"user_tz":0},"id":"c7ApoN2qU4pR"},"outputs":[],"source":["# initialize seed, mu, sigma, S0, paths, steps, T\n","# Clear pytorch cache\n","torch.cuda.empty_cache()\n","\n","# Set model parameters\n","seed = 36\n","num_stocks = 30\n","total_path = 50000\n","n_partition = 20\n","npaths = int(total_path/n_partition)\n","seq_length = 240\n","T=10\n","s0=np.array([1]*num_stocks)\n","mu = 0.12*s0\n","cov = 0.032*np.ones([num_stocks,num_stocks])\n","np.fill_diagonal(cov,0.16)\n","trade_cost = [0.01]*num_stocks\n","utility_gamma = 2.000\n","\n","# Set Simulation parameters: Notice that initial_rotate_matrix should be well guessed\n","n_epochs = 30\n","learning_rate = 0.01"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":1474,"status":"ok","timestamp":1679299413251,"user":{"displayName":"rua rua","userId":"08327814307539928376"},"user_tz":0},"id":"xeNg2PI4U6jb"},"outputs":[],"source":["# set up the trading costs\n","all_cost = np.ones([num_stocks,seq_length-1,total_path])\n","for i in range(num_stocks):\n","  all_cost[i,:,:] = trade_cost[i]\n","\n","# calculate rho: Notice the single is used only for plotting a 2 asset situation\n","if (num_stocks==2):\n","    rho = np.round(cov[0,1]/(np.sqrt(cov[0,0]*cov[1,1])),3)"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":4743,"status":"ok","timestamp":1679299263941,"user":{"displayName":"rua rua","userId":"08327814307539928376"},"user_tz":0},"id":"oNF8yLfOgyqQ"},"outputs":[],"source":["# To determine optimal trading frequency, based on Johannes Muhle-Karbe's paper, higher dimension waited to be verified\n","# step 1: Calculting the Markowitz optimal\n","Markowitz_opt = np.matmul(np.linalg.inv(cov),mu)/utility_gamma\n","Markowitz_opt_tensor =  torch.tensor(Markowitz_opt,dtype = torch.float).to(device)\n","# step 2: Define the distance for initial non trade region\n","delta = 0.1*np.power(np.diag(cov)*trade_cost/utility_gamma,1/3)\n","delta_tensor = torch.tensor(delta, dtype = torch.float).to(device)"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":45256,"status":"ok","timestamp":1679299554882,"user":{"displayName":"rua rua","userId":"08327814307539928376"},"user_tz":0},"id":"zuuFCdRyhFBQ"},"outputs":[],"source":["# Create a stock simulation with prices, returns\n","stock = dg.ManyStocks(seed,num_stocks,mu,s0,cov,total_path,seq_length-1,T)\n","returns = torch.tensor(stock.Returns(),dtype=torch.float).to(device)\n","# Create a default strategy as initial input, better use the optimal strategy without cost\n","strategy = (torch.tensor(Markowitz_opt,dtype=torch.float).view(num_stocks,1,1)*torch.ones((num_stocks,seq_length,total_path),dtype=torch.float)).to(device)\n","# Create a trading cost\n","cost =  torch.tensor(all_cost,dtype=torch.float).to(device)"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1679299559088,"user":{"displayName":"rua rua","userId":"08327814307539928376"},"user_tz":0},"id":"VHRgG19NhI79"},"outputs":[],"source":["# Calculate return of specific strategy\n","def cal_return(strat_partition, return_partition, cost_partition, n_iterations=5):\n","    r = torch.sum(strat_partition[:, :-1, :] * return_partition, 0)\n","    \n","    for _ in range(n_iterations):\n","        r = r - torch.sum(cost_partition * abs((r + 1) * strat_partition[:, 1:, :] - (return_partition + 1) * strat_partition[:, :-1, :]), axis=0)\n","        \n","    return r\n","\n","class Cal_return(nn.Module):\n","    def __init__(self):\n","        super().__init__()\n","\n","    def forward(self, strat_partition, return_partition, cost_partition):\n","        return cal_return(strat_partition, return_partition, cost_partition)"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":225,"status":"ok","timestamp":1679299568326,"user":{"displayName":"rua rua","userId":"08327814307539928376"},"user_tz":0},"id":"wxGKhzm-hN3T"},"outputs":[],"source":["# Define a log utility function\n","class LogUtilityLoss(torch.nn.Module):\n","    \n","    def __init__(self):\n","        super(LogUtilityLoss,self).__init__()\n","        \n","    def forward(self,x):\n","        loss = -torch.mean(torch.log(x))\n","        return loss\n","\n","# Define a power utility function\n","class PowerUtilityLoss(torch.nn.Module):\n","    \n","    def __init__(self,gamma):\n","        super(PowerUtilityLoss,self).__init__()\n","        self.gamma = gamma\n","        \n","    def forward(self,x):\n","        loss = -torch.mean((torch.pow(x,1-self.gamma)-1)/(1-self.gamma))\n","        return loss"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":232,"status":"ok","timestamp":1679299616025,"user":{"displayName":"rua rua","userId":"08327814307539928376"},"user_tz":0},"id":"XHkcIobdhQBR"},"outputs":[],"source":["# Customize a RNN layer with double relu for multiple assets\n","# considering returns data to build a changed strategy weight according to price change\n","class MyRNN(nn.Module):\n","\n","    def __init__(self, input_size, hidden_size, batch_size,dim_size):\n","        \"\"\"Initialize params.\"\"\"\n","        super(MyRNN, self).__init__()\n","        # read input parameters\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.batch_size = batch_size\n","        self.dim_size = dim_size\n","\n","        \n","        self.edge_coef = nn.Linear(dim_size,dim_size).to(device)\n","\n","                \n","    # Forward function allows a form:\n","    # h_t = w_fc2*relu(w_fc1*relu(w_inp*x_t+b_inp+w_h*h_{t-1}+b_h)+b_fc1)+b_fc2+b_fc1-b_h1\n","    def forward(self, input, returns_partition, hidden):\n","      # create the pi_bar(merton optimal) and identity matrix\n","      pi_bar = (torch.tensor(Markowitz_opt,dtype=torch.float).view(self.dim_size,self.hidden_size,self.hidden_size)*\\\n","                torch.ones((self.dim_size,self.hidden_size,npaths),dtype=torch.float)).to(device).squeeze(1)\n","      e_matrix = torch.eye(self.dim_size).to(device)\n","      \n","      def recurrence(input, returns_partition, hidden):\n","        #creating scalars, empty vectors and normalized v\n","        eps = 1e-5\n","        hidden = hidden.squeeze(1)\n","        hidden_temp = hidden\n","        judge_mat = torch.zeros([self.dim_size,self.batch_size],requires_grad=True).to(device)\n","        v = torch.nn.functional.normalize(self.edge_coef.weight, p=2.0, dim=1, eps=1e-12, out = None)\n","        \n","        # loop once to find the fitness of each asset\n","        for j in range(self.dim_size):\n","          # create v for each asset\n","          vj = torch.nn.functional.normalize(self.edge_coef.weight, p=2.0, dim=1, eps=1e-12, out = None)[j,:]\n","          # calculate lambda for all assets\n","          lambda_pi_plus = (torch.abs(self.edge_coef.bias[j])*torch.ones(self.batch_size).to(device) - torch.matmul(vj,hidden-pi_bar))/(torch.matmul(vj,e_matrix[j,:]))\n","          lambda_pi_minus = (-torch.abs(self.edge_coef.bias[j])*torch.ones(self.batch_size).to(device) - torch.matmul(vj,hidden-pi_bar))/(torch.matmul(vj,e_matrix[j,:]))\n","          hidden_new = hidden + (lambda_pi_plus.view(self.batch_size,1)*e_matrix[j,:]).T*(torch.matmul(vj,hidden-pi_bar)>torch.abs(self.edge_coef.bias[j]))+\\\n","                  (lambda_pi_minus.view(self.batch_size,1)*e_matrix[j,:]).T*(torch.matmul(vj,hidden-pi_bar)<-torch.abs(self.edge_coef.bias[j]))\n","          # create a matrix recording the fitness of such asset\n","          judge = (torch.matmul(v,hidden_new-pi_bar)<torch.abs(self.edge_coef.bias.view(self.dim_size,1))+eps) & (torch.matmul(v,hidden_new-pi_bar)>-torch.abs(self.edge_coef.bias.view(self.dim_size,1))-eps)\n","\n","          judge = torch.min(judge,0).values\n","          judge_mat[j,:] = judge\n","        # create a matrix recording the assets which project to notrade region with only one projection\n","        judge_mat = torch.max(judge_mat,0).values\n","        del hidden_new\n","        torch.cuda.empty_cache()\n","\n","        for j in range(self.dim_size):\n","          # create v for each asset\n","          vj = torch.nn.functional.normalize(self.edge_coef.weight, p=2.0, dim=1, eps=1e-12, out = None)[j,:]\n","          # calculate lambda for all assets\n","          lambda_pi_plus = (torch.abs(self.edge_coef.bias[j])*torch.ones(self.batch_size).to(device) - torch.matmul(vj,hidden_temp-pi_bar))/(torch.matmul(vj,e_matrix[j,:]))\n","          lambda_pi_minus = (-torch.abs(self.edge_coef.bias[j])*torch.ones(self.batch_size).to(device) - torch.matmul(vj,hidden_temp-pi_bar))/(torch.matmul(vj,e_matrix[j,:]))\n","          # one step projection of each asset\n","          hidden_temp = hidden_temp + (lambda_pi_plus.view(self.batch_size,1)*e_matrix[j,:]).T*(torch.matmul(vj,hidden_temp-pi_bar)>torch.abs(self.edge_coef.bias[j]))+\\\n","                  (lambda_pi_minus.view(self.batch_size,1)*e_matrix[j,:]).T*(torch.matmul(vj,hidden_temp-pi_bar)<-torch.abs(self.edge_coef.bias[j]))\n","\n","        del lambda_pi_plus\n","        del lambda_pi_minus\n","        torch.cuda.empty_cache()  \n","        # start a bisection method to find the exact boundary of assets without one fitness projection\n","        h_in =  pi_bar\n","        h_out = (1-judge_mat)*hidden\n","        for i in range(8):\n","          h_m = h_in+(-h_in+h_out)/2\n","          judge = (torch.matmul(v,h_m-pi_bar)<=torch.abs(self.edge_coef.bias.view(self.dim_size,1))+eps) & (torch.matmul(v,h_m-pi_bar)>=-torch.abs(self.edge_coef.bias.view(self.dim_size,1))-eps)\n","          judge = torch.min(judge,0).values\n","          h_out = (~judge)*h_m+(judge)*h_out\n","          h_in = (judge)*h_m+(~judge)*h_in\n","        hidden = (judge_mat*hidden_temp+(1-judge_mat)*h_m).unsqueeze(1)\n","        return hidden\n","\n","\n","      output = []\n","      steps = range(input.size(1))\n","      #myret = returns\n","      for i in steps:\n","          if i ==0:\n","              hidden = input[:,0,:].view(self.dim_size,1,self.batch_size).to(device)\n","              #hidden = (torch.tensor(Markowitz_opt,dtype=torch.float).view(self.dim_size,1,1)*torch.ones((self.dim_size,1,self.batch_size),dtype=torch.float)).to(device)\n","          else:\n","              # pi_t = myrotate(pi_{t-1}*(1+r_t)/(1+sum(pi_{t-1}*r_t))) due to change of price after rebalance\n","              adjust_pi = hidden.view(self.dim_size,1,self.batch_size)*(1+returns_partition[:,i-1,:].view(self.dim_size,1,self.batch_size))\\\n","                                    /(1+torch.sum(hidden.view(self.dim_size,1,self.batch_size)*returns_partition[:,i-1,:].view(self.dim_size,1,\\\n","                                    self.batch_size),0))\n","                                    \n","                           \n","\n","              hidden = recurrence(input[:,i,:].view(self.dim_size,self.input_size,self.batch_size), returns_partition, adjust_pi)\n","            \n","          output.append(hidden)\n","\n","      output = torch.cat(output, 1)\n","\n","      return output, hidden"]},{"cell_type":"code","execution_count":17,"metadata":{"executionInfo":{"elapsed":242,"status":"ok","timestamp":1679299657160,"user":{"displayName":"rua rua","userId":"08327814307539928376"},"user_tz":0},"id":"VpH_uEM8hUlv"},"outputs":[],"source":["class SimpleRNN(nn.Module):\n","    def __init__(self, input_size, hidden_size, n_layers, batch_size, seq_length, dim_size):\n","        super(SimpleRNN, self).__init__()\n","        self.input_size = input_size\n","        self.hidden_size = hidden_size\n","        self.n_layers = n_layers\n","        self.batch_size = batch_size\n","        self.seq_length = seq_length\n","        self.dim_size = dim_size\n","        # the rnn layer which works as out, hidden_t = f(out_(t), hidden_(t-1)), used to approximate pi^*_(t)= f(pi^*_(t-1),pi_t)\n","        self.rnn = MyRNN(input_size, hidden_size, batch_size, dim_size).to(device)\n","        self.out = nn.Linear(dim_size, hidden_size,bias=False).to(device)\n","        # initialize some bias and weight\n","        self.rnn.edge_coef.bias = torch.nn.Parameter(delta_tensor)\n","        self.rnn.edge_coef.weight = torch.nn.Parameter(torch.eye(self.dim_size).to(device))\n","        self.out.weight = torch.nn.Parameter(*torch.ones_like(self.out.weight))\n","\n","    def step(self, input, returns_partition, cost_partition, hidden=None):\n","        output, hidden = self.rnn(input, returns_partition, hidden).to(device)\n","        output2 = self.out.weight.view(dim_size,hidden_size,hidden_size)*output\n","        return output, output2\n","\n","    def forward(self, inputs, returns_partition, cost_partition, hidden=None):\n","        hidden = self.__init__hidden().to(device)\n","        output, hidden = self.rnn(inputs.float(), returns_partition, hidden.float())\n","        # output2 the overall wealth at time T\n","        output2 = torch.prod(cal_return(output,returns_partition,cost_partition).to(device)+1,0)\n","        return  output, output2\n","        #return  output\n","        \n","    def __init__hidden(self):\n","        hidden = strategy[:,0,:].to(device)\n","        return hidden"]},{"cell_type":"code","execution_count":18,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1679299696667,"user":{"displayName":"rua rua","userId":"08327814307539928376"},"user_tz":0},"id":"EEDqctHkhYcS"},"outputs":[],"source":["input_size = 1\n","hidden_size = 1\n","n_layers = 1\n","batch_size = npaths\n","seq_length = seq_length\n","dim_size = num_stocks\n","\n","model = SimpleRNN(input_size, hidden_size, n_layers, batch_size, seq_length,dim_size).to(device)\n","#criterion = LogUtilityLoss()\n","criterion = PowerUtilityLoss(utility_gamma)\n","model = model.to(torch.float32)\n","model.out.weight.requires_grad = False\n","optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=learning_rate)\n","#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=1)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"T4pDnSOzNUey","outputId":"966e9cd0-8b17-4ad1-9bb0-f3899a1ee05a"},"outputs":[{"output_type":"stream","name":"stdout","text":["0 tensor(-0.5982, device='cuda:0', grad_fn=<NegBackward0>)\n","Epoch-0 lr: 0.01\n","10 tensor(-0.5984, device='cuda:0', grad_fn=<NegBackward0>)\n","Epoch-10 lr: 0.01\n","20 tensor(-0.5989, device='cuda:0', grad_fn=<NegBackward0>)\n","Epoch-20 lr: 0.01\n"]}],"source":["losses = np.zeros(n_epochs+1) \n","loss = 0\n","for epoch in range(n_epochs+1):\n","  for batches in range(n_partition):\n","    fina_strat, outputs = model(strategy.to(device)[:,:,batches*npaths:(batches+1)*npaths], returns[:,:,batches*npaths:(batches+1)*npaths],cost[:,:,batches*npaths:(batches+1)*npaths], None)\n","    loss = criterion(outputs)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","  #scheduler.step()\n","    \n","  losses[epoch] += loss\n","  if epoch % 10 == 0:\n","      print(epoch, loss)\n","      print('Epoch-{0} lr: {1}'.format(epoch, optimizer.param_groups[0]['lr']))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jj-B-uqphkUt"},"outputs":[],"source":["# Plot loss curve\n","epochs = range(n_epochs+1)\n","\n","fig, ax = plt.subplots()\n","ax.plot(epochs, losses)\n","\n","ax.set(xlabel='Epochs', ylabel='Loss',\n","       title='Loss')\n","ax.grid()\n","from google.colab import files\n","#fig.savefig(\"loss_correl{}_mu{}_sigma{}.png\".format(rho,mu,np.diag(cov)), format='png', dpi=500)\n","#files.download(\"loss_correl{}_mu{}_sigma{}.png\".format(rho,mu,np.diag(cov))) \n","\n","plt.show()\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":827,"status":"ok","timestamp":1677226643180,"user":{"displayName":"YYF ROTZ","userId":"08327814307539928376"},"user_tz":0},"id":"gvR5EBzjhlAI","outputId":"9cc3bfda-70b3-4ab6-e1a6-3bdcb13fa8e3"},"outputs":[{"name":"stdout","output_type":"stream","text":["rnn.edge_coef.weight tensor([[ 1.0906, -0.0413, -0.0050],\n","        [-0.0252,  1.0960, -0.0367],\n","        [ 0.0195, -0.0319,  1.1005]], device='cuda:0')\n","rnn.edge_coef.bias tensor([0.0843, 0.0831, 0.0734], device='cuda:0')\n","out.weight tensor([1., 1., 1.], device='cuda:0')\n"]}],"source":["# output the weights and bias of the model parameter\n","for name, param in model.named_parameters():\n","     print (name, param.data)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mdw5e8yyuV1X"},"outputs":[],"source":["# Plain plot of 2 chosen dimensions of assets\n","ex_strategy = torch.rand([num_stocks,seq_length,npaths]).to(device).view([num_stocks,seq_length,npaths])\n","o = model(ex_strategy)[0]\n","x = o.cpu().detach().numpy()[0,7,:].reshape([1,npaths])\n","y = o.cpu().detach().numpy()[1,7,:].reshape([1,npaths])\n","#z = o.cpu().detach().numpy()[2,7,:].reshape([1,npaths])\n","plt.figure(figsize=(6,5))\n","#plt.xlim((0.05,0.25))\n","#plt.ylim((0.05,0.25))\n","#plt.xticks(np.arange(0.05,0.25,0.05))\n","#plt.yticks(np.arange(0.05,0.25,0.05))\n","plt.grid()\n","plt.title(label='No trade Region')\n","plt.plot(x, y, 'o', color='blue')\n","plt.savefig(\"mu{}_sigmasquare{}.png\".format(mu,np.diag(cov)), format='png', dpi=500)\n","files.download(\"mu{}_sigmasquare{}.png\".format(mu,np.diag(cov)))\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"ZKoRel5Kwkd2"},"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"iqGPWQOdHjKP"},"outputs":[],"source":["# Comparison between different ESR, notice this is specially defined for the liquid and illiquid case\n","# Calculate the simulated ESR\n","ESR_Simulation = torch.log(torch.pow(torch.mean(torch.pow(outputs,1-utility_gamma)),1/(1-utility_gamma)))/T\n","# Calculate the rho matrix\n","rho_matrix = cov/np.sqrt(np.diag(cov))/((np.sqrt(np.diag(cov))).T)\n","# Creating beta alpha and sigma_I\n","beta = np.zeros([num_stocks,num_stocks-1])\n","sigma_I = np.zeros([num_stocks,1])\n","lambda_I = np.zeros([num_stocks,1])\n","pi_bar = np.zeros([num_stocks,1])\n","reduction = np.zeros([num_stocks,1])\n","for s in range(num_stocks):\n","  rho_s = np.delete(rho_matrix,s,1)[s,:]\n","  sigma_temp = np.delete(np.delete(cov,s,0),s,1)\n","  vec_temp = np.delete(cov,s,0)[:,s]\n","  beta[s,:] = np.matmul(np.linalg.inv(sigma_temp),vec_temp)\n","  sigma_I[s] = cov[s,s]*(1-np.matmul(rho_s,rho_s.T))\n","  pi_bar[s] = (mu[s]-np.matmul(beta[s,:],np.delete(mu,s,0).T))/(sigma_I[s]*utility_gamma)\n","  lambda_I[s] = np.power((0.75*utility_gamma*utility_gamma*pi_bar[s]*pi_bar[s]*sigma_I[s]*sigma_I[s]*\\\n","                 (np.matmul(np.matmul((vec_temp-np.delete(mu,s,0)).T,np.linalg.inv(sigma_temp)),(vec_temp-np.delete(mu,s,0)))+(1-pi_bar[s])*(1-pi_bar[s])*sigma_I[s]))*trade_cost[s],1/3)\n","  reduction[s] = np.power(lambda_I[s],2)/(2*sigma_I[s]*utility_gamma)\n","ESR_Theo_max = np.matmul(np.matmul(mu.T,np.linalg.inv(cov)),mu)/2/utility_gamma-np.max(reduction)\n","ESR_Theo_min = np.matmul(np.matmul(mu.T,np.linalg.inv(cov)),mu)/2/utility_gamma-np.sum(reduction)\n","print(ESR_Simulation)\n","print(ESR_Theo_max)\n","print(ESR_Theo_min)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"a-RzXiXnSerb"},"outputs":[],"source":["# Plot of rotating gif figure of 3-d assets\n","ex_strategy = torch.rand([num_stocks,seq_length,npaths]).to(device).view([num_stocks,seq_length,npaths])\n","o = model(ex_strategy)[0]\n","fig = plt.figure()\n","ax = Axes3D(fig)\n","x = o.cpu().detach().numpy()[0,10,:].reshape([1,npaths])\n","y = o.cpu().detach().numpy()[1,10,:].reshape([1,npaths])\n","z = o.cpu().detach().numpy()[2,10,:].reshape([1,npaths])\n","\n","#ax.scatter(x, y, z, marker='.',color='blue');\n","def init():\n","    ax.scatter(x, y, z, marker='.', s=20, c=\"blue\", alpha=0.6)\n","    return fig,\n","\n","def animate(i):\n","    ax.view_init(elev=10., azim=i)\n","    return fig,\n","\n","# Animate\n","anim = animation.FuncAnimation(fig, animate, init_func=init,\n","                               frames=180, interval=20, blit=True,repeat = True)\n","\n","\n","writer = animation.PillowWriter(fps=15,metadata=dict(artist='Me'),bitrate=900)\n","anim.save('scatter.gif', writer=writer)\n","files.download('scatter.gif');"]}],"metadata":{"accelerator":"GPU","colab":{"machine_shape":"hm","provenance":[],"mount_file_id":"1HUxZn0Dhu0Qmf9USdQi2CeD28Mp_2UEv","authorship_tag":"ABX9TyOrIzmJ/kYUscVoykpH06Q1"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}